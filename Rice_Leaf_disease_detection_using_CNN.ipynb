{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Rice Leaf disease detection using CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaypatil99/RICE-LEAF-DISEASE-DETECTION/blob/main/Rice_Leaf_disease_detection_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdEvy3X4G7aL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgADlbpWG7aQ"
      },
      "source": [
        "# Problem Defination\n",
        "- Rice Leaf Disease using CNN\n",
        "- They are three different types of classes and each class is one disease type\n",
        "1.Bacterial Leaf Blight\n",
        "\n",
        "- The disease is most likely to develop in areas that have weeds and stubbles of infected plants.\n",
        "- It can occur in both tropical and temperate environments, particularly in irrigated and rainfed lowland areas.\n",
        "- In general, the disease favors temperatures at 25−34°C, with relative humidity above 70%.\n",
        "\n",
        "\n",
        "2.Brown Spot\n",
        "\n",
        "- Brown spot has been historically largely ignored as one of the most common and most damaging rice diseases.\n",
        "- Brown spot is a fungal disease that infects the coleoptile, leaves, leaf sheath, panicle branches, glumes, and spikelets.\n",
        "- The disease can develop in areas with high relative humidity (86−100%) and temperature between 16 and 36°C.\n",
        "- It is common in unflooded and nutrient-deficient soil, or in soils that accumulate toxic substances.\n",
        "\n",
        "\n",
        "3.Leaf Smut\n",
        "\n",
        "- Leaf smut, caused by the fungus Entyloma oryzae, is a widely distributed, but somewhat minor, disease of rice.\n",
        "- The fungus produces slightly raised, angular, black spots (sori) on both sides of the leaves.\n",
        "- Although rare, it also can produce spots on leaf sheaths.\n",
        "- The black spots are about 0.5 to 5.0 millimeters long\n",
        "- Now,the task is to identify the disease type occured to Rice leaf,When we provide a leaf with disease"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TLj0_BJG7aW"
      },
      "source": [
        "### Now,the task is to identify the disease type occured to Rice leaf,When we provide a leaf with disease"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-VtfKXlG7aY"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32v0KO2AG7aZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation,Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "import glob\n",
        "import shutil\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4m897w-G7ac"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYKKRA4EG7ad"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0yZ74rVG7ag"
      },
      "source": [
        "model.add(Conv2D(64, (3,3), input_shape=(250, 250, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5RiPxE1G7aj"
      },
      "source": [
        "# Adding Flatten and Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXy2vjq7G7al"
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnYto5WKG7am"
      },
      "source": [
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0mMZjmCG7an"
      },
      "source": [
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4pVg6ZIG7an"
      },
      "source": [
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkOKkjQgG7ao"
      },
      "source": [
        "# Adding softmax as Activation,As of its an Multiclass classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6SAdQNEG7ap"
      },
      "source": [
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kQ18VowG7ap",
        "outputId": "2667ff0c-d832-4452-b7a3-429cacdef026"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 248, 248, 64)      1792      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 248, 248, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 124, 124, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 32)      18464     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 122, 122, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 59, 59, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 59, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 27, 27, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 3, 3, 32)          9248      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 165       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 74,085\n",
            "Trainable params: 74,085\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-frSKL1zG7as"
      },
      "source": [
        "model.compile (\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wtx-kGTG7at"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kssn0ikHG7au"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale= 1/255\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a_bsbiUG7au"
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKJQZnQ2G7au"
      },
      "source": [
        "# Training and Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwVnrJd_G7av",
        "outputId": "b7e3e531-6d48-4036-a1e7-906bd841b13f"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"Rice Leaf\\Train\",\n",
        "    target_size= (250, 250),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    \"Rice Leaf\\Test\",\n",
        "    target_size= (250, 250),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 90 images belonging to 3 classes.\n",
            "Found 29 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZyiPdnSG7av"
      },
      "source": [
        "opt=keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYHlO26aG7aw",
        "outputId": "038bec59-87f6-4d46-f574-69277e8b6835"
      },
      "source": [
        "model.fit_generator(train_generator,\n",
        "                    epochs=38,\n",
        "                    verbose=2,\n",
        "                    validation_data=test_generator\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/38\n",
            "3/3 - 9s - loss: 1.0678 - accuracy: 0.3889 - val_loss: 0.9488 - val_accuracy: 0.5172\n",
            "Epoch 2/38\n",
            "3/3 - 9s - loss: 1.0478 - accuracy: 0.3444 - val_loss: 0.9602 - val_accuracy: 0.3103\n",
            "Epoch 3/38\n",
            "3/3 - 9s - loss: 1.0196 - accuracy: 0.3444 - val_loss: 0.8528 - val_accuracy: 0.4483\n",
            "Epoch 4/38\n",
            "3/3 - 9s - loss: 0.9735 - accuracy: 0.3889 - val_loss: 0.8392 - val_accuracy: 0.6897\n",
            "Epoch 5/38\n",
            "3/3 - 9s - loss: 0.9176 - accuracy: 0.5667 - val_loss: 0.7376 - val_accuracy: 0.6897\n",
            "Epoch 6/38\n",
            "3/3 - 9s - loss: 0.8874 - accuracy: 0.5444 - val_loss: 0.7275 - val_accuracy: 0.6552\n",
            "Epoch 7/38\n",
            "3/3 - 9s - loss: 0.8741 - accuracy: 0.5667 - val_loss: 0.7016 - val_accuracy: 0.6897\n",
            "Epoch 8/38\n",
            "3/3 - 9s - loss: 0.7976 - accuracy: 0.6333 - val_loss: 0.6643 - val_accuracy: 0.7931\n",
            "Epoch 9/38\n",
            "3/3 - 9s - loss: 0.8529 - accuracy: 0.5778 - val_loss: 0.9088 - val_accuracy: 0.5862\n",
            "Epoch 10/38\n",
            "3/3 - 9s - loss: 1.0806 - accuracy: 0.4444 - val_loss: 0.9258 - val_accuracy: 0.5517\n",
            "Epoch 11/38\n",
            "3/3 - 9s - loss: 0.9362 - accuracy: 0.5333 - val_loss: 0.7965 - val_accuracy: 0.6897\n",
            "Epoch 12/38\n",
            "3/3 - 9s - loss: 0.8525 - accuracy: 0.6000 - val_loss: 0.7925 - val_accuracy: 0.5862\n",
            "Epoch 13/38\n",
            "3/3 - 9s - loss: 0.8229 - accuracy: 0.5333 - val_loss: 0.7549 - val_accuracy: 0.5862\n",
            "Epoch 14/38\n",
            "3/3 - 9s - loss: 0.7753 - accuracy: 0.5889 - val_loss: 0.6752 - val_accuracy: 0.6207\n",
            "Epoch 15/38\n",
            "3/3 - 9s - loss: 0.6428 - accuracy: 0.6444 - val_loss: 0.5866 - val_accuracy: 0.7931\n",
            "Epoch 16/38\n",
            "3/3 - 9s - loss: 0.5827 - accuracy: 0.8222 - val_loss: 0.4654 - val_accuracy: 0.7931\n",
            "Epoch 17/38\n",
            "3/3 - 9s - loss: 1.0861 - accuracy: 0.5889 - val_loss: 0.7100 - val_accuracy: 0.5517\n",
            "Epoch 18/38\n",
            "3/3 - 9s - loss: 0.8191 - accuracy: 0.6333 - val_loss: 0.7660 - val_accuracy: 0.6552\n",
            "Epoch 19/38\n",
            "3/3 - 9s - loss: 1.0353 - accuracy: 0.4556 - val_loss: 0.9067 - val_accuracy: 0.5517\n",
            "Epoch 20/38\n",
            "3/3 - 10s - loss: 1.0208 - accuracy: 0.4000 - val_loss: 0.8505 - val_accuracy: 0.4138\n",
            "Epoch 21/38\n",
            "3/3 - 9s - loss: 0.9491 - accuracy: 0.4000 - val_loss: 0.7602 - val_accuracy: 0.6207\n",
            "Epoch 22/38\n",
            "3/3 - 10s - loss: 0.8887 - accuracy: 0.5556 - val_loss: 0.7472 - val_accuracy: 0.6552\n",
            "Epoch 23/38\n",
            "3/3 - 10s - loss: 0.8545 - accuracy: 0.5889 - val_loss: 0.7057 - val_accuracy: 0.6897\n",
            "Epoch 24/38\n",
            "3/3 - 10s - loss: 0.8154 - accuracy: 0.6556 - val_loss: 0.6790 - val_accuracy: 0.7241\n",
            "Epoch 25/38\n",
            "3/3 - 10s - loss: 0.7537 - accuracy: 0.6778 - val_loss: 0.6504 - val_accuracy: 0.7586\n",
            "Epoch 26/38\n",
            "3/3 - 10s - loss: 0.7079 - accuracy: 0.7333 - val_loss: 0.6201 - val_accuracy: 0.7931\n",
            "Epoch 27/38\n",
            "3/3 - 11s - loss: 0.7395 - accuracy: 0.7000 - val_loss: 0.5971 - val_accuracy: 0.7931\n",
            "Epoch 28/38\n",
            "3/3 - 10s - loss: 0.6625 - accuracy: 0.7333 - val_loss: 0.5702 - val_accuracy: 0.7931\n",
            "Epoch 29/38\n",
            "3/3 - 10s - loss: 0.6112 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.8276\n",
            "Epoch 30/38\n",
            "3/3 - 10s - loss: 0.5711 - accuracy: 0.8444 - val_loss: 0.4130 - val_accuracy: 0.9310\n",
            "Epoch 31/38\n",
            "3/3 - 10s - loss: 0.5467 - accuracy: 0.8333 - val_loss: 0.6492 - val_accuracy: 0.7241\n",
            "Epoch 32/38\n",
            "3/3 - 10s - loss: 0.4736 - accuracy: 0.7667 - val_loss: 0.3482 - val_accuracy: 0.8621\n",
            "Epoch 33/38\n",
            "3/3 - 10s - loss: 0.3549 - accuracy: 0.9000 - val_loss: 0.5171 - val_accuracy: 0.6552\n",
            "Epoch 34/38\n",
            "3/3 - 10s - loss: 0.5088 - accuracy: 0.8222 - val_loss: 0.3065 - val_accuracy: 0.9310\n",
            "Epoch 35/38\n",
            "3/3 - 10s - loss: 0.4776 - accuracy: 0.8222 - val_loss: 0.4588 - val_accuracy: 0.7931\n",
            "Epoch 36/38\n",
            "3/3 - 10s - loss: 0.6379 - accuracy: 0.7444 - val_loss: 0.4125 - val_accuracy: 0.8276\n",
            "Epoch 37/38\n",
            "3/3 - 10s - loss: 0.4532 - accuracy: 0.8222 - val_loss: 0.4295 - val_accuracy: 0.7586\n",
            "Epoch 38/38\n",
            "3/3 - 10s - loss: 0.4171 - accuracy: 0.8333 - val_loss: 0.3697 - val_accuracy: 0.8621\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1faaa64e250>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9bJpkbaG7aw"
      },
      "source": [
        "### Therefore at the end accuracy of Rice Leaf Disease 83%,by taking epchos as 38 and layers to six"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84IEPKPPG7ax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}